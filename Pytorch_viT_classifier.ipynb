{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ecbfca5-8626-4546-976c-c64b08b119b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e16e58b8-842d-43a2-b808-2f5979da465f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/4Z1fwRR295-1O3PMQBH6Dg/images-dataSAT.tar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d35e886-60b8-41fc-8299-4ff056317f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write permissions available for downloading and extracting the dataset tar file\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e128df09b2d43e68e086755673ba79f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading images-dataSAT.tar:   0%|          | 0/20243456 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40e961baf5d84674a252c0f685298f51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6003 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to '.'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import skillsnetwork\n",
    "\n",
    "def check_skillnetwork_extraction(extract_dir):\n",
    "    \"\"\"Check if the environment allows symlink creation for download/extraction.\"\"\"\n",
    "    symlink_test = os.path.join(extract_dir, \"symlink_test\")\n",
    "    if not os.path.exists(symlink_test):\n",
    "        os.symlink(os.path.join(os.sep, \"tmp\"), symlink_test)\n",
    "        print(\"Write permissions available for downloading and extracting the dataset tar file\")\n",
    "        os.unlink(symlink_test)\n",
    "\n",
    "async def download_tar_dataset(url, tar_path, extract_dir):\n",
    "    \"\"\"Download and extract dataset tar file asynchronously.\"\"\"\n",
    "    if not os.path.exists(tar_path):\n",
    "        try:\n",
    "            print(f\"Downloading from {url}...\")\n",
    "            import httpx\n",
    "            async with httpx.AsyncClient() as client:\n",
    "                response = await client.get(url, follow_redirects=True)\n",
    "                response.raise_for_status()\n",
    "                with open(tar_path, \"wb\") as f:\n",
    "                    f.write(response.content)\n",
    "            print(f\"Successfully downloaded '{tar_path}'.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Download error: {e}\")\n",
    "    else:\n",
    "        print(f\"Dataset tar file already exists at: {tar_path}\")\n",
    "    import tarfile\n",
    "    with tarfile.open(tar_path, 'r:*') as tar_ref:\n",
    "        tar_ref.extractall(path=extract_dir)\n",
    "        print(f\"Successfully extracted to '{extract_dir}'.\")\n",
    "\n",
    "try:\n",
    "    check_skillnetwork_extraction(data_dir)\n",
    "    await skillsnetwork.prepare(url=dataset_url, path=data_dir, overwrite=True)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(\"Primary download/extraction method failed.\")\n",
    "    print(\"Falling back to manual download and extraction...\")\n",
    "    import tarfile\n",
    "    import httpx\n",
    "    from pathlib import Path\n",
    "    file_name = Path(dataset_url).name\n",
    "    tar_path = os.path.join(data_dir, file_name)\n",
    "    await download_tar_dataset(dataset_url, tar_path, data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d2be560-862b-4c9e-9224-d19abecd33f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def download_model(url, model_path):\n",
    "    if not os.path.exists(model_path):\n",
    "        try:\n",
    "            print(f\"Downloading from {url}...\")\n",
    "            import httpx\n",
    "            async with httpx.AsyncClient() as client:\n",
    "                response = await client.get(url, follow_redirects=True)\n",
    "                response.raise_for_status()\n",
    "                with open(model_path, \"wb\") as f:\n",
    "                    f.write(response.content)\n",
    "            print(f\"Successfully downloaded '{model_path}'.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Download error: {e}\")\n",
    "    else:\n",
    "        print(f\"Model file already downloaded at: {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21b47bf0-3574-4cb5-86c9-b32e0ba93b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model file already downloaded at: ./pytorch_cnn_vit_ai_capstone_model_state_dict.pth\n"
     ]
    }
   ],
   "source": [
    "pytorch_state_dict_url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/rFBrDlu1NNcAzir5Uww8eg/pytorch-cnn-vit-ai-capstone-model-state-dict.pth\"\n",
    "pytorch_state_dict_name = \"pytorch_cnn_vit_ai_capstone_model_state_dict.pth\"\n",
    "pytorch_state_dict_path = os.path.join(data_dir, pytorch_state_dict_name)\n",
    "\n",
    "await download_model(pytorch_state_dict_url, pytorch_state_dict_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0386b98d-4c23-4673-aab5-3117de80e356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.4 ms, sys: 19.3 ms, total: 36.6 ms\n",
      "Wall time: 2.82 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%capture captured_output\n",
    "%pip install scikit-learn==1.7.0 tensorflow==2.19 numpy==1.26 matplotlib==3.9.2 skillsnetwork\n",
    "%pip install torch==2.8.0+cpu torchvision==0.23.0+cpu torchaudio==2.8.0+cpu \\\n",
    "    --index-url https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc20f33b-8cf0-44cb-be8b-bcf77db577ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported libraries\n",
      "CPU times: user 2.22 s, sys: 391 ms, total: 2.61 s\n",
      "Wall time: 2.71 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import time\n",
    "import httpx\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "#import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import  random_split\n",
    "import torch.nn.functional as F\n",
    "\n",
    "print(\"Imported libraries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "393e31f6-0756-4382-ba28-180cc47139a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 2.19.0  |  GPUs found: []\n",
      "CPU times: user 100 μs, sys: 30 μs, total: 130 μs\n",
      "Wall time: 134 μs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import tensorflow as tf\n",
    "gpu_list = tf.config.list_physical_devices('GPU')\n",
    "device = \"gpu\" if gpu_list != [] else \"cpu\"\n",
    "print(f\"TensorFlow {tf.__version__}  |  GPUs found: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "090626bd-8923-43ab-8d08-a4347674b69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global seed set to 7331 - Processes are now deterministic.\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed: int = 42) -> None:\n",
    "    \"\"\"Seed Python, NumPy, tensorflow, and PyTorch (CPU & all GPUs) and\n",
    "    make cuDNN run in deterministic mode.\"\"\"\n",
    "    # ---- Python and NumPy -------------------------------------------\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # ---- Tensorflow -------------------------------------------------\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "    # ---- PyTorch (CPU  &  GPU) --------------------------------------\n",
    "    torch.manual_seed(seed)            \n",
    "    torch.cuda.manual_seed_all(seed)   \n",
    "\n",
    "    # ---- cuDNN: force repeatable convolutions -----------------------\n",
    "    torch.backends.cudnn.deterministic = True \n",
    "    torch.backends.cudnn.benchmark     = False \n",
    "\n",
    "#====================\n",
    "SEED = 7331\n",
    "set_seed(SEED)\n",
    "print(f\"Global seed set to {SEED} - Processes are now deterministic.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29b3a80e-7625-4685-8f59-17eeaf0d2755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the pre-trained PyTorch model:\n",
      "pytorch_cnn_vit_ai_capstone_model_state_dict.pth --at------> ./pytorch_cnn_vit_ai_capstone_model_state_dict.pth\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(pytorch_state_dict_path):\n",
    "    print(\"Unable to find the PyTorch model at give path. Please check...\")\n",
    "else:\n",
    "    print(f\"Found the pre-trained PyTorch model:\\n{pytorch_state_dict_name} --at------> {pytorch_state_dict_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "922191d4-0afb-474f-a1dd-c9400f059461",
   "metadata": {},
   "outputs": [],
   "source": [
    "#====================\n",
    "class ConvNet(nn.Module):\n",
    "    ''' \n",
    "    Class to define the architecture same as the imported pre-trained CNN model\n",
    "    '''\n",
    "    def __init__(self, num_classes: int):\n",
    "        super().__init__()\n",
    "        # -------- convolutional feature extractor --------\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32,  kernel_size=5, padding=2), nn.ReLU(inplace=True), nn.MaxPool2d(2), nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(32, 64,  kernel_size=5, padding=2), nn.ReLU(inplace=True), nn.MaxPool2d(2), nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(64, 128, kernel_size=5, padding=2), nn.ReLU(inplace=True), nn.MaxPool2d(2), nn.BatchNorm2d(128),\n",
    "            nn.Conv2d(128, 256, kernel_size=5, padding=2), nn.ReLU(inplace=True), nn.MaxPool2d(2), nn.BatchNorm2d(256),\n",
    "            nn.Conv2d(256, 512, kernel_size=5, padding=2), nn.ReLU(inplace=True), nn.MaxPool2d(2), nn.BatchNorm2d(512),\n",
    "            nn.Conv2d(512, 1024, kernel_size=5, padding=2), nn.ReLU(inplace=True), nn.MaxPool2d(2), nn.BatchNorm2d(1024),\n",
    "        )\n",
    "\n",
    "        # -------- global pooling + classifier head --------\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.classifier = nn.Sequential(nn.Flatten(),                           # flatten feature map of dimensions (1024 × 1 × 1) to 1024\n",
    "                                        nn.Linear(1024, 2048), nn.ReLU(inplace=True), nn.BatchNorm1d(2048), nn.Dropout(0.4), \n",
    "                                        nn.Linear(2048, num_classes)\n",
    "                                       )\n",
    "\n",
    "    def forward_features(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.features(x)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.forward_features(x)   # features, dimensions:(B, 1024, H', W')\n",
    "        x = self.pool(x)               # global-average-pooling, dimensions: (B, 1024, 1, 1)\n",
    "        x = self.classifier(x)         # classifier, dimensions: (B, num_classes)\n",
    "        return x\n",
    "\n",
    "#====================\n",
    "class PatchEmbed(nn.Module):\n",
    "    def __init__(self, input_channel=1024, embed_dim=768):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Conv2d(input_channel, embed_dim, kernel_size=1)  # 1×1 conv\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.proj(x).flatten(2).transpose(1, 2)  # (B,L,D)\n",
    "        return x\n",
    "\n",
    "#====================\n",
    "class MHSA(nn.Module):\n",
    "    def __init__(self, dim, heads=8, dropout=0.):\n",
    "        super().__init__()\n",
    "        self.heads = heads\n",
    "        self.scale = (dim // heads) ** -0.5\n",
    "        self.qkv = nn.Linear(dim, dim * 3)\n",
    "        self.attn_drop = nn.Dropout(dropout)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.proj_drop = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        B, N, D = x.shape\n",
    "        q, k, v = self.qkv(x).chunk(3, dim=-1)\n",
    "        q = q.reshape(B, N, self.heads, -1).transpose(1, 2)  # (B, heads, N, d)\n",
    "        k = k.reshape(B, N, self.heads, -1).transpose(1, 2)\n",
    "        v = v.reshape(B, N, self.heads, -1).transpose(1, 2)\n",
    "        attn = torch.matmul(q, k.transpose(-2, -1)) * self.scale\n",
    "        attn = self.attn_drop(attn.softmax(dim=-1))\n",
    "        x = torch.matmul(attn, v).transpose(1, 2).reshape(B, N, D)\n",
    "        return self.proj_drop(self.proj(x))\n",
    "\n",
    "#====================\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, dim, heads, mlp_ratio=4., dropout=0.):\n",
    "        super().__init__()\n",
    "        self.norm1 = nn.LayerNorm(dim)\n",
    "        self.attn  = MHSA(dim, heads, dropout)\n",
    "        self.norm2 = nn.LayerNorm(dim)\n",
    "        self.mlp   = nn.Sequential(\n",
    "                                    nn.Linear(dim, int(dim * mlp_ratio)),\n",
    "                                    nn.GELU(), nn.Dropout(dropout),\n",
    "                                    nn.Linear(int(dim * mlp_ratio), dim),\n",
    "                                    nn.Dropout(dropout))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.norm1(x))\n",
    "        x = x + self.mlp(self.norm2(x))\n",
    "        return x\n",
    "\n",
    "#====================\n",
    "class ViT(nn.Module):\n",
    "    def __init__(self, in_ch=1024, num_classes=2,\n",
    "                 embed_dim=768, depth=6, heads=8,\n",
    "                 mlp_ratio=4., dropout=0.1, max_tokens=50):\n",
    "        super().__init__()\n",
    "        self.patch = PatchEmbed(in_ch, embed_dim)           # 1×1 conv\n",
    "        self.cls   = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
    "        self.pos   = nn.Parameter(torch.randn(1, max_tokens, embed_dim))\n",
    "        self.blocks = nn.ModuleList([\n",
    "            TransformerBlock(embed_dim, heads, mlp_ratio, dropout)\n",
    "            for _ in range(depth)])\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "        self.head = nn.Linear(embed_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):                          # x: (B,C,H,W)\n",
    "        x = self.patch(x)                          # (B,L,D)\n",
    "        B, L, _ = x.shape\n",
    "        cls = self.cls.expand(B, -1, -1)           # (B,1,D)\n",
    "        x = torch.cat((cls, x), 1)                 # (B,L+1,D)\n",
    "        x = x + self.pos[:, :L + 1]                # match seq-len\n",
    "        for blk in self.blocks:\n",
    "            x = blk(x)\n",
    "        return self.head(self.norm(x)[:, 0])       # CLS token\n",
    "\n",
    "#====================\n",
    "class CNN_ViT_Hybrid(nn.Module):\n",
    "    def __init__(self, num_classes=2, embed_dim=768, depth=6, heads=8):\n",
    "        super().__init__()\n",
    "        self.cnn = ConvNet(num_classes)            # load weights later\n",
    "        self.vit = ViT(num_classes=num_classes,\n",
    "                       embed_dim=embed_dim,\n",
    "                       depth=depth,\n",
    "                       heads=heads)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.vit(self.cnn.forward_features(x))\n",
    "\n",
    "#====================\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        loss_sum, correct = 0, 0\n",
    "        for batch_idx, (x, y) in enumerate(tqdm(loader, desc=\"Validation\")):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            out = model(x)\n",
    "            loss = criterion(out, y)\n",
    "            loss_sum += loss.item() * x.size(0)\n",
    "            correct  += (out.argmax(1) == y).sum().item()\n",
    "    return loss_sum / len(loader.dataset), correct / len(loader.dataset)# Set device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e934db1d-0c70-4294-8b70-055dbe8d79c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Please use the space below to write your answer\n",
    "dataset_path = os.path.join(data_dir, \"images_dataSAT\")\n",
    "\n",
    "img_w, img_h = 64, 64\n",
    "batch_size = 128\n",
    "num_classes = 2\n",
    "agri_class_labels = [\"non-agri\", \"agri\"]\n",
    "\n",
    "depth = 3\n",
    "attn_heads = 6\n",
    "embed_dim = 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2928654a-08a4-41dc-a53d-8e830f5511f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((img_w, img_h)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "full_dataset = datasets.ImageFolder(dataset_path, transform=train_transform)\n",
    "test_loader = DataLoader(full_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97c84892-2f03-4a17-89df-a60cff84aa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Please use the space below to write your answer\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "pytorch_model = CNN_ViT_Hybrid(num_classes=num_classes,\n",
    "                      heads=attn_heads,\n",
    "                      depth=depth,\n",
    "                      embed_dim=embed_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ab9d151-00c2-49e8-9e4e-39baf2f471fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model state dict, now getting predictions\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained CNN-ViT hybrid model weights \n",
    "if device==\"cpu\":\n",
    "    map_location=torch.device(\"cpu\")\n",
    "else:\n",
    "    map_location=torch.device(\"cuda\")\n",
    "\n",
    "pytorch_model.load_state_dict(torch.load(pytorch_state_dict_path, map_location=map_location), strict=False)\n",
    "print(\"Loaded model state dict, now getting predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "73e4790a-469c-422e-a697-b50578435478",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step: 100%|██████████| 47/47 [01:25<00:00,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 4s, sys: 17 s, total: 1min 21s\n",
      "Wall time: 1min 25s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "all_preds_pytorch = []\n",
    "all_labels_pytorch = []\n",
    "all_probs_pytorch = []\n",
    "\n",
    "pytorch_model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (images, labels) in enumerate(tqdm(test_loader, desc=\"Step\")):\n",
    "#    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = pytorch_model(images)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        probs = F.softmax(outputs, dim=1)[:, 1]  # probability for class 1\n",
    "        all_probs_pytorch.extend(probs.cpu())\n",
    "        all_preds_pytorch.extend(preds.cpu().numpy().flatten())\n",
    "        all_labels_pytorch.extend(labels.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a93a3a6-97f1-4c22-af23-21d838bf25c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28.2 ms, sys: 11.9 ms, total: 40.1 ms\n",
      "Wall time: 44.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.metrics import (accuracy_score,\n",
    "                             precision_score,\n",
    "                             recall_score,\n",
    "                             f1_score,\n",
    "                             roc_curve, \n",
    "                             roc_auc_score,\n",
    "                             log_loss,\n",
    "                             classification_report,\n",
    "                             confusion_matrix,\n",
    "                             ConfusionMatrixDisplay,\n",
    "                            )\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# define a function to get the metrics comprehensively\n",
    "def model_metrics(y_true, y_pred, y_prob, class_labels):\n",
    "    y_prob = np.array(y_prob)\n",
    "    if len(y_prob.shape)<2:\n",
    "        roc_score = roc_auc_score(y_true, y_prob)\n",
    "    elif len(y_prob.shape)==2:\n",
    "        roc_score = roc_auc_score(y_true, y_prob[:,1])\n",
    "    else:\n",
    "        roc_score = np.nan\n",
    "    metrics = {'Accuracy': accuracy_score(y_true, y_pred),\n",
    "               'Precision': precision_score(y_true, y_pred),\n",
    "               'Recall': recall_score(y_true, y_pred),\n",
    "               'Loss': log_loss(y_true, y_prob),\n",
    "               'F1 Score': f1_score(y_true, y_pred),\n",
    "               'ROC-AUC': roc_score,\n",
    "               'Confusion Matrix': confusion_matrix(y_true, y_pred),\n",
    "               'Classification Report': classification_report(y_true, y_pred, target_names=class_labels, digits=4),\n",
    "               \"Class labels\": class_labels\n",
    "              }\n",
    "    return metrics\n",
    "\n",
    "#function to print the metrics\n",
    "def print_metrics(y_true, y_pred, y_prob, class_labels, model_name):\n",
    "    metrics = model_metrics(y_true, y_pred, y_prob, class_labels)\n",
    "    \n",
    "    print(f\"Evaluation metrics for the \\033[1m{model_name}\\033[0m\")\n",
    "    print(f\"Accuracy: {'':<1}{metrics[\"Accuracy\"]:.4f}\")\n",
    "    if metrics[\"ROC-AUC\"] != np.nan:\n",
    "        print(f\"ROC-AUC: {'':<2}{metrics[\"ROC-AUC\"]:.4f}\")\n",
    "    print(f\"Loss: {'':<5}{metrics[\"Loss\"]:.4f}\\n\")\n",
    "    print(f\"Classification report:\\n\\n  {metrics[\"Classification Report\"]}\")\n",
    "    print(\"========= Confusion Matrix =========\")\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=metrics[\"Confusion Matrix\"],\n",
    "                                  display_labels=metrics[\"Class labels\"])\n",
    "\n",
    "    disp.plot()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e09d9503-a8ff-4bc5-97da-7019ff69d2cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation metrics for the \u001b[1mPytorch CNN-Vit Hybrid Model\u001b[0m\n",
      "Accuracy:  0.9990\n",
      "ROC-AUC:   1.0000\n",
      "Loss:      0.0047\n",
      "\n",
      "Classification report:\n",
      "\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    non-agri     0.9990    0.9990    0.9990      3000\n",
      "        agri     0.9990    0.9990    0.9990      3000\n",
      "\n",
      "    accuracy                         0.9990      6000\n",
      "   macro avg     0.9990    0.9990    0.9990      6000\n",
      "weighted avg     0.9990    0.9990    0.9990      6000\n",
      "\n",
      "========= Confusion Matrix =========\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Please use the space below to write your answer\n",
    "print_metrics(all_labels_pytorch, all_preds_pytorch, all_probs_pytorch, agri_class_labels, \n",
    "    'Pytorch CNN-Vit Hybrid Model'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a2a830-dcb0-4d13-ac49-0cd647849234",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
